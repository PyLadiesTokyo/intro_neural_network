{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 後ほどグラフを描画するために使います\n",
    "# 先に実行しておいて下さい\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Machine Learning with Python\n",
    "\n",
    "機械学習を理論から理解して使いこなすには2時間では収まらない時間が必要です．  \n",
    "なので，ここでは割りきって「とにかく使ってみる」「雰囲気を知る」を目標に，Python の `scikit-learn` という機械学習用ライブラリにフォーカスしながら機械学習の一連の流れを体験していきます．  \n",
    "※意：細かい説明はしません．また説明は正確ではないです．\n",
    "\n",
    "いきなり手書き数字のデータを扱うのはちょっと難易度が高いので，もっと簡単なデータを使って機械学習の大雑把な流れを把握していきます．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 正解データを利用して未知データを予測・分類する問題\n",
    "\n",
    "今回は，正解が分かっているデータを利用して，未知のデータを予測→分類する問題に取り組みます．  \n",
    "「正解が分かっているデータを利用して，未知のデータを予測→分類する問題」とはどのような問題でしょうか？  \n",
    "以下に例を挙げてみます．\n",
    "\n",
    "- 身長 / 体重 / 性別のデータを利用して，新たに与えられた身長 / 体重の組み合わせから性別を予測→分類\n",
    "- 気温や気圧およびそのときの天気のデータを利用して，新たに与えられた気温や気圧から天気を予測→分類\n",
    "\n",
    "今回取り組む「手書きの数字を認識して何の数字が書かれているのか予測→分類」する問題も，はじめに大量の手書き数字とその手書き数字に対応する数字のデータが与えられます．そのデータを利用して，新たに与えられた手書き数字が何の数字に対応するのかを予測します．\n",
    "\n",
    "ここで大事なのは，分類の規則の作り方です（e.g. 身長や体重のデータから性別を予測する規則を作る）  \n",
    "正解が分かっているデータから分類の規則を作っていくことを__学習__とよびます．\n",
    "\n",
    "ここで説明のために以下のような記号を使います\n",
    "\n",
    "- train_set: 正解データ（学習に利用するデータ）\n",
    "  - X: 予測に利用するデータ (e.g. 身長 / 体重)\n",
    "  - y: 予測したい対象 (e.g. 性別)\n",
    "  \n",
    "`X` に対応する `y` から，学習を行って分類の規則を作ります．\n",
    "\n",
    "どれだけ正しく分類規則が作れたか，評価するためのデータも用意しておきましょう．\n",
    "  \n",
    "- test_set: テストデータ（未知データ）\n",
    "  - X_test: 予測に利用するデータ\n",
    "  - y_test: 予測したい対象．分類結果が正しかったかどうか確認するために用いる（本来であれば分からない）\n",
    "  \n",
    "説明が長くなってしまいました．  \n",
    "何やらぼんやりとしていて分かりにくいかもしれませんが，とにかくやってみましょう．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 正解データとテストデータの用意\n",
    "\n",
    "まず最初にデータを用意します．  \n",
    "ここでは，データを用意する過程については説明しないので，何かやってる・・・位の理解で大丈夫です．  \n",
    "以下を実行して下さい．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.datasets import make_moons, make_classification\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "\n",
    "X, y = make_classification(n_features=2, n_redundant=0, n_informative=2,\n",
    "                           random_state=1, n_clusters_per_class=1)\n",
    "rng = np.random.RandomState(2)\n",
    "X += 2 * rng.uniform(size=X.shape)\n",
    "X, y = make_moons(noise=0.3, random_state=0)\n",
    "X = StandardScaler().fit_transform(X)\n",
    "\n",
    "X, X_test, y, y_test = train_test_split(X, y, test_size=.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上記の処理により，以下の4つのデータが作成されています．\n",
    "\n",
    "- 正解データ\n",
    "  - X: 予測に利用するデータ\n",
    "  - y: 予測したい対象\n",
    "- テストデータ\n",
    "  - X_test: 予測に利用するデータ\n",
    "  - y_test: 予測したい対象．分類結果が正しかったかどうか確認するために用いる\n",
    "  \n",
    "まずは学習に必要な正解データの中身を見ていきます．  \n",
    "X，yのデータの大きさを確認しましょう（どちらも行列です）  \n",
    "\n",
    "※詰まる方は1つ目のNotebookに戻っておさらいしましょう！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Xのデータの大きさを確認\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# yのデータの大きさを確認\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Xとyの上から10行の中身を確認しましょう（列は全て表示）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Xの上から10行の中身を確認（列は全て表示）\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# yの10行の中身を確認\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "これだけでもデータについて色々な情報が得られました．  \n",
    "予測に利用するデータの種類は2種類で，各データは小数で表されています．これらのデータを利用して，結果が0であるか1であるかを予想するようです．\n",
    "\n",
    "予測に利用するデータの種類が2種類しかない（＝2次元のデータな）ので，折角なのでデータの様子をグラフで描画して確認してみましょう．  \n",
    "以下を実行して下さい．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 6))\n",
    "\n",
    "plt.scatter(X[:, 0], X[:, 1], s=50, marker='o', c=y)  # 青: y=0，赤: y=1\n",
    "\n",
    "plt.xlabel('X[:, 0]')\n",
    "plt.ylabel('X[:, 1]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "青い点で示されるデータと赤い点で示されるデータを分類する規則を学習したいです．  \n",
    "目で見ると何となく分け方が分かる気がしますね！"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データの分類規則を学習する\n",
    "\n",
    "データの分類規則をどうやって学習するか？ここが機械学習の肝となる部分です．  \n",
    "ですがそこを理解するためには最低限の数学の知識が必要となるため，このハンズオンではその点を説明しません．  \n",
    "Pythonの `scikit-learn` というライブラリを使うと，知識がなくても何となくの分類規則なら学習することが出来ます．\n",
    "\n",
    "※最適な分類規則を得るためには，パラメータ調整が必須です  \n",
    "※くどいですが，現実世界の問題では何となく動かせるだけではどうしようもない\n",
    "\n",
    "今回は `RBF SVM` という分類器を利用して，分類規則を学習します．  \n",
    "以下を実行してみましょう．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "classifier = SVC(gamma=2, C=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使う分類器（およびパラメータ）を指定したら，`classifier.fit(X, y)` というコマンドを実行するだけで，分類規則を学習します．驚きの手軽さ！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifier.fit(X, y)  # これを実行するだけで分類規則の学習は終了"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "分類性能を調べてみましょう．\n",
    "\n",
    "`cal_z` は分類器の分類性能を計算してくれる関数です．  \n",
    "中身の説明はしないので，とりあえず実行して次に進んで下さい．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_min, x_max = X[:, 0].min() - .5, X[:, 0].max() + .5\n",
    "y_min, y_max = X[:, 1].min() - .5, X[:, 1].max() + .5\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.2), np.arange(y_min, y_max, 0.2))\n",
    "\n",
    "def cal_z(clf):\n",
    "    if hasattr(clf, \"decision_function\"):\n",
    "        z = clf.decision_function(np.c_[xx.ravel(), yy.ravel()])\n",
    "    else:\n",
    "        z = clf.predict_proba(np.c_[xx.ravel(), yy.ravel()])[:, 1]\n",
    "        \n",
    "    return z.reshape(xx.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`cal_z` を利用して分類器の分類性能を図示してみます．  \n",
    "以下を実行して下さい．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 6))\n",
    "\n",
    "plt.contourf(xx, yy, cal_z(classifier), alpha=.4)       # 分類器の分類性能をヒートマップ形式で表示\n",
    "plt.scatter(X[:, 0], X[:, 1], s=50, marker='o', c=y)  # 正解データ点を表示"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "この分類器は，青い領域にあるデータを0，赤い領域にあるデータを1に分類します．  \n",
    "色が濃いほど分類結果に自信があることを意味しています．\n",
    "\n",
    "非常に高い精度で分類規則を学習出来ている気がしますね！  \n",
    "ここに，分類を行いたいテストデータも追加して見てみましょう．  \n",
    "以下を実行して下さい．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 6))\n",
    "\n",
    "plt.contourf(xx, yy, cal_z(classifier), alpha=.4)\n",
    "plt.scatter(X[:, 0], X[:, 1], s=50, marker='o', c=y)\n",
    "plt.scatter(X_test[:, 0], X_test[:, 1], s=50, marker='x', c=y_test)  # テストデータを表示する処理を追加"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "テストデータもうまく分類できそうです．\n",
    "\n",
    "`classifier.score` を利用して，テストデータに対する分類の精度を数値で確認することもできます．  \n",
    "以下を実行して下さい．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# テストデータに対する分類の正解率 [%]\n",
    "\n",
    "100 * classifier.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ここまでが一連の手順です．  \n",
    "今回の流れをもう一度おさらいすると，\n",
    "\n",
    "- データの中身を確認\n",
    "- 分類に利用する規則（アルゴリズム）を決定 / パラメータを決定　※今回あまり触れません\n",
    "- classifier.fit(X, y) でデータをうまく分類する規則を学習\n",
    "- 分類性能を確認\n",
    "  - plt.contourf(xx, yy, cal_z(classifier), alpha=.4)  # 分類性能のヒートマップを表示\n",
    "  - plt.scatter(X[:, 0], X[:, 1], s=50, marker='o', c=y)  # 分類規則を学習する際に利用するデータを表示\n",
    "  - plt.scatter(X_test[:, 0], X_test[:, 1], s=50, marker='x', c=y_test)  # 分類を行いたいテストデータを表示\n",
    "- classifier.score(X_test, y_test) でテストデータに対する分類性能を確認\n",
    "\n",
    "利用するアルゴリズムはどう決定するの？パラメータはどうするの？クロスバリデーションやらないの？・・・etc.  \n",
    "まだまだ考えることは山程ありますが，ここでは以上の説明にとどめておきます．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 発展課題（時間があまりそうなら）\n",
    "\n",
    "今回利用した `RBF SVM` の他にも様々な分類器があります．  \n",
    "以下の分類器の中から一つ選んで，同じように分類規則を学習してみましょう．結果はどう変化しましたか？  \n",
    "※ちゃんと動かしてないので問題あったら連絡下さい＼(^o^)／ｗ\n",
    "\n",
    "\n",
    "- Nearest Neighbors\n",
    "\n",
    "```python\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "classifier = KNeighborsClassifier(3)\n",
    "```\n",
    "\n",
    "- Linear SVM\n",
    "\n",
    "```python\n",
    "from sklearn.svm import SVC\n",
    "classifier = SVC(kernel=\"linear\", C=0.025)\n",
    "```\n",
    "\n",
    "- Decision Tree\n",
    "\n",
    "```python\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "classifier = DecisionTreeClassifier(max_depth=5)\n",
    "```\n",
    "\n",
    "- Random Forest\n",
    "\n",
    "```python\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "classifier = RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1)\n",
    "```\n",
    "\n",
    "- AdaBoost\n",
    "\n",
    "```python\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "classifier = AdaBoostClassifier()\n",
    "```\n",
    "\n",
    "- Naive Bayes\n",
    "\n",
    "```python\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "classifier = GaussianNB()\n",
    "```\n",
    "\n",
    "- Linear Discriminant Analysis\n",
    "\n",
    "```python\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "classifier = LinearDiscriminantAnalysis()\n",
    "```\n",
    "\n",
    "- Quadratic Discriminant Analysis\n",
    "\n",
    "```python\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "classifier = QuadraticDiscriminantAnalysis()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
